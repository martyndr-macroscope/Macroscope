{"id":"W2099611016","title":"Communication lower bounds and optimal algorithms for numerical linear algebra","authors":["Grey Ballard","Erin Carson","James Demmel","Mark Frederick Hoemmen","Nicholas Knight","Oded Schwartz"],"venue":"Acta Numerica","year":2014,"doi":"10.1017/s0962492914000038","url":"https://doi.org/10.1017/s0962492914000038","openalex":"https://openalex.org/W2099611016","abstract":"The traditional metric for the efficiency of a numerical algorithm has been the number of arithmetic operations it performs. Technological trends have long been reducing the time to perform an arithmetic operation, so it is no longer the bottleneck in many algorithms; rather, communication , or moving data, is the bottleneck. This motivates us to seek algorithms that move as little data as possible, either between levels of a memory hierarchy or between parallel processors over a network. In this paper we summarize recent progress in three aspects of this problem. First we describe lower bounds on communication. Some of these generalize known lower bounds for dense classical (O(n 3 )) matrix multiplication to all direct methods of linear algebra, to sequential and parallel algorithms, and to dense and sparse matrices. We also present lower bounds for Strassen-like algorithms, and for iterative methods, in particular Krylov subspace methods applied to sparse matrices. Second, we compare these lower bounds to widely used versions of these algorithms, and note that these widely used algorithms usually communicate asymptotically more than is necessary. Third, we identify or invent new algorithms for most linear algebra problems that do attain these lower bounds, and demonstrate large speed-ups in theory and practice.","is_oa":false,"oa_status":null,"network":{"internal_citations":3,"cited_by_count":121},"references":229,"networkCitations":3,"seed":false}