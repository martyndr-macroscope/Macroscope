{"id":"W3165904677","title":"Fit without fear: remarkable mathematical phenomena of deep learning through the prism of interpolation","authors":["Mikhail Belkin"],"venue":"Acta Numerica","year":2021,"doi":"10.1017/s0962492921000039","url":"https://doi.org/10.1017/s0962492921000039","openalex":"https://openalex.org/W3165904677","abstract":"In the past decade the mathematical theory of machine learning has lagged far behind the triumphs of deep neural networks on practical challenges. However, the gap between theory and practice is gradually starting to close. In this paper I will attempt to assemble some pieces of the remarkable and still incomplete mathematical mosaic emerging from the efforts to understand the foundations of deep learning. The two key themes will be interpolation and its sibling over-parametrization. Interpolation corresponds to fitting data, even noisy data, exactly. Over-parametrization enables interpolation and provides flexibility to select a suitable interpolating model. As we will see, just as a physical prism separates colours mixed within a ray of light, the figurative prism of interpolation helps to disentangle generalization and optimization properties within the complex picture of modern machine learning. This article is written in the belief and hope that clearer understanding of these issues will bring us a step closer towards a general theory of deep learning and machine learning.","is_oa":true,"oa_status":null,"network":{"internal_citations":1,"cited_by_count":22},"references":108,"networkCitations":1,"seed":false}