{"id":"W4376144198","title":"Floating-point arithmetic","authors":["Sylvie Boldo","Claude-Pierre Jeannerod","Guillaume Melquiond","Jean‐Michel Muller"],"venue":"Acta Numerica","year":2023,"doi":"10.1017/s0962492922000101","url":"https://doi.org/10.1017/s0962492922000101","openalex":"https://openalex.org/W4376144198","abstract":"Floating-point numbers have an intuitive meaning when it comes to physics-based numerical computations, and they have thus become the most common way of approximating real numbers in computers. The IEEE-754 Standard has played a large part in making floating-point arithmetic ubiquitous today, by specifying its semantics in a strict yet useful way as early as 1985. In particular, floating-point operations should be performed as if their results were first computed with an infinite precision and then rounded to the target format. A consequence is that floating-point arithmetic satisfies the ‘standard model’ that is often used for analysing the accuracy of floating-point algorithms. But that is only scraping the surface, and floating-point arithmetic offers much more. In this survey we recall the history of floating-point arithmetic as well as its specification mandated by the IEEE-754 Standard. We also recall what properties it entails and what every programmer should know when designing a floating-point algorithm. We provide various basic blocks that can be implemented with floating-point arithmetic. In particular, one can actually compute the rounding error caused by some floating-point operations, which paves the way to designing more accurate algorithms. More generally, properties of floating-point arithmetic make it possible to extend the accuracy of computations beyond working precision.","is_oa":true,"oa_status":null,"network":{"internal_citations":1,"cited_by_count":20},"references":162,"networkCitations":1,"seed":false}