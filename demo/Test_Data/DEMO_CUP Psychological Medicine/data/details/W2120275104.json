{"id":"W2120275104","title":"Event-related potential examination of facial affect processing in bipolar disorder and schizophrenia","authors":["Jonathan K. Wynn","Carol Jahshan","Lori L. Altshuler","David C. Glahn","Michael F. Green"],"venue":"Psychological Medicine","year":2012,"doi":"10.1017/s0033291712001006","url":"https://doi.org/10.1017/s0033291712001006","openalex":"https://openalex.org/W2120275104","abstract":"Background Patients with bipolar disorder exhibit consistent deficits in facial affect identification at both behavioral and neural levels. However, little is known about which stages of facial affect processing are dysfunctional. Method Event-related potentials (ERPs), including amplitude and latency, were used to evaluate two stages of facial affect processing: N170 to examine structural encoding of facial features and N250 to examine decoding of facial features in 57 bipolar disorder patients, 30 schizophrenia patients and 30 healthy controls. Three conditions were administered: participants were asked to identify the emotion of a face, the gender of a face, or whether a building was one or two stories tall. Results Schizophrenia patients' emotion identification accuracy was lower than that of bipolar patients and healthy controls. N170 amplitude was significantly smaller in schizophrenia patients compared to bipolar patients and healthy controls, which did not differ from each other. Both patient groups had significantly longer N170 latency compared to healthy controls. For N250, both patient groups showed significantly smaller amplitudes compared with controls, but did not differ from each other. Bipolar patients showed longer N250 latency than healthy controls; patient groups did not differ from each other. Conclusions Bipolar disorder patients have relatively intact structural encoding of faces (N170) but are impaired when decoding facial features for complex judgments about faces (N250 latency and amplitude), such as identifying emotion or gender.","is_oa":true,"oa_status":null,"network":{"internal_citations":0,"cited_by_count":58},"references":41,"networkCitations":0,"seed":false}