{"id":"W2564414954","title":"Biases in research: risk factors for non-replicability in psychotherapy and pharmacotherapy research","authors":["Falk Leichsenring","Allan Abbass","Mark J. Hilsenroth","Frank Leweke","Patrick Luyten","John R. Keefe","Nick Midgley","Sven Rabung","Simone Salzer","C. Steinert"],"venue":"Psychological Medicine","year":2016,"doi":"10.1017/s003329171600324x","url":"https://doi.org/10.1017/s003329171600324x","openalex":"https://openalex.org/W2564414954","abstract":"Replicability of findings is an essential prerequisite of research. For both basic and clinical research, however, low replicability of findings has recently been reported. Replicability may be affected by research biases not sufficiently controlled for by the existing research standards. Several biases such as researcher allegiance or selective reporting are well-known for affecting results. For psychotherapy and pharmacotherapy research, specific additional biases may affect outcome (e.g. therapist allegiance, therapist effects or impairments in treatment implementation). For meta-analyses further specific biases are relevant. In psychotherapy and pharmacotherapy research these biases have not yet been systematically discussed in the context of replicability. Using a list of 13 biases as a starting point, we discuss each bias's impact on replicability. We illustrate each bias by selective findings of recent research, showing that (1) several biases are not yet sufficiently controlled for by the presently applied research standards, (2) these biases have a pernicious effect on replicability of findings. For the sake of research credibility, it is critical to avoid these biases in future research. To control for biases and to improve replicability, we propose to systematically implement several measures in psychotherapy and pharmacotherapy research, such as adversarial collaboration (inviting academic rivals to collaborate), reviewing study design prior to knowing the results, triple-blind data analysis (including subjects, investigators and data managers/statisticians), data analysis by other research teams (crowdsourcing), and, last not least, updating reporting standards such as CONSORT or the Template for Intervention Description and Replication (TIDieR).","is_oa":false,"oa_status":null,"network":{"internal_citations":3,"cited_by_count":72},"references":100,"networkCitations":3,"seed":false}