{"id":"W4405449369","title":"Advancing the personalized advantage index (PAI): a systematic review and application in two large multi-site samples in anxiety disorders","authors":["Charlotte Meinke","Silvan Hornstein","Johanna Schmidt","Volker Arolt","Udo Dannlowski","Jürgen Deckert","Katharina Domschke","Lydia Fehm","Thomas Fydrich","Alexander L. Gerlach","Alfons O. Hamm","Ingmar Heinig","Jürgen Hoyer","Tilo Kircher","Katja Koelkebeck","Thomas Lang�","Jürgen Margraf","Peter Neudeck","Paul Pauli","Jan Richter","Winfried Rief","Silvia Schneider","Benjamin Straube","Andreas Ströhle","Hans‐Ulrich Wïttchen","Peter Zwanzger","Henrik Walter","Ulrike Lueken","Andre Pittig","Kevin Hilbert"],"venue":"Psychological Medicine","year":2024,"doi":"10.1017/s0033291724003118","url":"https://doi.org/10.1017/s0033291724003118","openalex":"https://openalex.org/W4405449369","abstract":"Abstract Background The Personalized Advantage Index (PAI) shows promise as a method for identifying the most effective treatment for individual patients. Previous studies have demonstrated its utility in retrospective evaluations across various settings. In this study, we explored the effect of different methodological choices in predictive modelling underlying the PAI. Methods Our approach involved a two-step procedure. First, we conducted a review of prior studies utilizing the PAI, evaluating each study using the Prediction model study Risk Of Bias Assessment Tool (PROBAST). We specifically assessed whether the studies adhered to two standards of predictive modeling: refraining from using leave-one-out cross-validation (LOO CV) and preventing data leakage. Second, we examined the impact of deviating from these methodological standards in real data. We employed both a traditional approach violating these standards and an advanced approach implementing them in two large-scale datasets, PANIC-net ( n = 261) and Protect-AD ( n = 614). Results The PROBAST-rating revealed a substantial risk of bias across studies, primarily due to inappropriate methodological choices. Most studies did not adhere to the examined prediction modeling standards, employing LOO CV and allowing data leakage. The comparison between the traditional and advanced approach revealed that ignoring these standards could systematically overestimate the utility of the PAI. Conclusion Our study cautions that violating standards in predictive modeling may strongly influence the evaluation of the PAI's utility, possibly leading to false positive results. To support an unbiased evaluation, crucial for potential clinical application, we provide a low-bias, openly accessible, and meticulously annotated script implementing the PAI.","is_oa":true,"oa_status":null,"network":{"internal_citations":4,"cited_by_count":3},"references":68,"networkCitations":4,"seed":false}